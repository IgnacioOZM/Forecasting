trControl = ctrl_tune,
metric = "RMSE")
mlp.fit #information about the resampling settings
ggplot(mlp.fit)+scale_x_log10()
plotnet(mlp.fit$finalModel) #Plot the network
SensAnalysisMLP(mlp.fit) #Statistical sensitivity analysis
#------------ Neural network --------------------------------
set.seed(150) #For replication
mlp.fit = train(form = Price~Demand+Wind+WD_lag1+Price_lag1+DEM_lag1, #Use formula method to account for categorical variables
data = fdata_tr,
method = "nnet",
linout = TRUE,
# tuneGrid = data.frame(size =5, decay = 0),
tuneGrid = expand.grid(size = seq(1,7,length.out = 7), decay=c(10^(-7),10^(-6),10^(-5),0.0001,0.001)),
maxit = 3000,
preProcess = c("center","scale"),
trControl = ctrl_tune,
metric = "RMSE")
mlp.fit #information about the resampling settings
ggplot(mlp.fit)+scale_x_log10()
#------------ Neural network --------------------------------
set.seed(150) #For replication
mlp.fit = train(form = Price~Demand+Wind+WD_lag1+Price_lag1+DEM_lag1, #Use formula method to account for categorical variables
data = fdata_tr,
method = "nnet",
linout = TRUE,
# tuneGrid = data.frame(size =5, decay = 0),
tuneGrid = expand.grid(size = seq(2,7,length.out = 7), decay=c(10^(-7),10^(-6),10^(-5),0.0001,0.001)),
maxit = 3000,
preProcess = c("center","scale"),
trControl = ctrl_tune,
metric = "RMSE")
mlp.fit #information about the resampling settings
ggplot(mlp.fit)+scale_x_log10()
#------------ Neural network --------------------------------
set.seed(150) #For replication
mlp.fit = train(form = Price~Demand+Wind+WD_lag1+Price_lag1+DEM_lag1, #Use formula method to account for categorical variables
data = fdata_tr,
method = "nnet",
linout = TRUE,
# tuneGrid = data.frame(size =5, decay = 0),
tuneGrid = expand.grid(size = seq(2,7,length.out = 6), decay=c(10^(-7),10^(-6),10^(-5),0.0001,0.001)),
maxit = 3000,
preProcess = c("center","scale"),
trControl = ctrl_tune,
metric = "RMSE")
mlp.fit #information about the resampling settings
ggplot(mlp.fit)+scale_x_log10()
ggplot(mlp.fit)
ggplot(mlp.fit)+scale_x_log10()
ggplot(mlp.fit)
#------------ Neural network --------------------------------
set.seed(150) #For replication
mlp.fit = train(form = Price~Demand+Wind+WD_lag1+Price_lag1+DEM_lag1, #Use formula method to account for categorical variables
data = fdata_tr,
method = "nnet",
linout = TRUE,
# tuneGrid = data.frame(size =5, decay = 0),
tuneGrid = expand.grid(size = seq(3, 5,length.out =2), decay=c(0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10)),
maxit = 2000,
preProcess = c("center","scale"),
trControl = ctrl_tune,
metric = "RMSE")
mlp.fit #information about the resampling settings
ggplot(mlp.fit)+scale_x_log10()
ggplot(mlp.fit)+scale_x_log10()
mlp.fit = train(form = Price~Demand+Wind+WD_lag1+Price_lag1+DEM_lag1, #Use formula method to account for categorical variables
data = fdata_tr,
method = "nnet",
linout = TRUE,
# tuneGrid = data.frame(size =5, decay = 0),
tuneGrid = expand.grid(size = seq(3, 5,length.out =2), decay=c(0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10)),
maxit = 3000,
preProcess = c("center","scale"),
trControl = ctrl_tune,
metric = "RMSE")
mlp.fit #information about the resampling settings
ggplot(mlp.fit)+scale_x_log10()
seq(2,5,length.out = 4)
seq(2:5)
#------------ Neural network --------------------------------
set.seed(150) #For replication
mlp.fit = train(form = Price~Demand+Wind+WD_lag1+Price_lag1+DEM_lag1, #Use formula method to account for categorical variables
data = fdata_tr,
method = "nnet",
linout = TRUE,
# tuneGrid = data.frame(size =5, decay = 0),
tuneGrid = expand.grid(size = seq(2,5,length.out = 4), decay=c(10^(-7),10^(-6),10^(-5),0.0001,0.001,0.01,0.1,1,10)),
maxit = 3000,
preProcess = c("center","scale"),
trControl = ctrl_tune,
metric = "RMSE")
mlp.fit #information about the resampling settings
ggplot(mlp.fit)+scale_x_log10()
#Predict training data
mlp_pred = predict(mlp.fit,  newdata = fdata_tr)
PlotModelDiagnosis(fdata_tr[,-1], fdata_tr[,4], mlp_pred, together = TRUE)
#Error measurements
accuracy(fdata_tr[,4],mlp_pred)
#Error measurements
accuracy(fdata_tr[,4],mlp_pred)
PlotModelDiagnosis(fdata_tr[,-1], fdata_tr[,4], mlp_pred, together = TRUE)
#Error measurements
accuracy(fdata_tr[,4],mlp_pred)
plot(fdata_tr[,4],type="l")
lines(mlp_pred,col = "red")
## Forecast for new data with h = 90
fdata <- read.csv("DailyPrice_Load_Wind_Spain_2019_2020.csv",sep = ";")
fdata_tr <- fdata[fdata$Date <= '2020-09-30',]
fdata_ts <- fdata[fdata$Date > '2020-09-30',]
fdata.Reg.new <- fdata_ts[,c(2,3,4)]
#create auxiliary output variable
fdata.Reg.new$Price <- rep(NA,length(fdata.Reg.new[,1]))
#join the datasets
fdata.join <- rbind(fdata_tr[,c(2:4)],fdata.Reg.new)
#create lagged variables
fdata.join$WD_lag1 <- Lag(fdata.join$Wind,1)
fdata.join$Price_lag1 <- Lag(fdata.join$Price,1)
fdata.join$DEM_lag1 <- Lag(fdata.join$Demand,1)
#loop for forecasting
tstart = dim(fdata_tr)[1]
for (i in (tstart+1):(tstart+92)){
#Predict and substitute in output variable so it can be used in following forecasts
fdata.join$Price[i] <- predict(mlp.fit,  newdata = fdata.join[i,])
#Recalculate lagged variables using the estimated value
fdata.join$DEM_lag1 <- Lag(fdata.join$Demand,1)
}
#forecasts
fdata.join$Price[(tstart+1):(tstart+92)]
y.MLP.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.MLP.est[i] <- fdata.join$Price[i]
}
#Plot series and forecast
autoplot(y)+
forecast::autolayer(y.MLP.est)
#Plot series and forecast
autoplot(y)+
forecast::autolayer(y.MLP.est)
y.MLP.est
## Forecast for new data with h = 90
fdata <- read.csv("DailyPrice_Load_Wind_Spain_2019_2020.csv",sep = ";")
fdata_tr <- fdata[fdata$Date <= '2020-09-30',]
fdata_ts <- fdata[fdata$Date > '2020-09-30',]
fdata.Reg.new <- fdata_ts[,c(2,3,4)]
#create auxiliary output variable
fdata.Reg.new$Price <- rep(NA,length(fdata.Reg.new[,1]))
fdata.Reg.new
#create auxiliary output variable
fdata.Reg.new$Price <- rep(NA,length(fdata.Reg.new[,1]))
#join the datasets
fdata.join <- rbind(fdata_tr[,c(2:4)],fdata.Reg.new)
fdata.join
#create lagged variables
fdata.join$WD_lag1 <- Lag(fdata.join$Wind,1)
fdata.join$Price_lag1 <- Lag(fdata.join$Price,1)
fdata.join$DEM_lag1 <- Lag(fdata.join$Demand,1)
#loop for forecasting
tstart = dim(fdata_tr)[1]
for (i in (tstart+1):(tstart+92)){
#Predict and substitute in output variable so it can be used in following forecasts
fdata.join$Price[i] <- predict(mlp.fit,  newdata = fdata.join[i,])
#Recalculate lagged variables using the estimated value
fdata.join$DEM_lag1 <- Lag(fdata.join$Demand,1)
}
#forecasts
fdata.join$Price[(tstart+1):(tstart+92)]
tstart = dim(fdata_tr)[1]
tstart
tstart
tstart+92
i=2
i=650
i=641
predict(mlp.fit,  newdata = fdata.join[i,])
newdata = fdata.join[i,]
newdata
#Recalculate lagged variables using the estimated value
fdata.join$Price_lag1 <- Lag(fdata.join$Price,1)
fdata.join[i,]
predict(mlp.fit,  newdata = fdata.join[i,])
## Forecast for new data with h = 90
fdata <- read.csv("DailyPrice_Load_Wind_Spain_2019_2020.csv",sep = ";")
fdata_tr <- fdata[fdata$Date <= '2020-09-30',]
fdata_ts <- fdata[fdata$Date > '2020-09-30',]
fdata.Reg.new <- fdata_ts[,c(2,3,4)]
#create auxiliary output variable
fdata.Reg.new$Price <- rep(NA,length(fdata.Reg.new[,1]))
#join the datasets
fdata.join <- rbind(fdata_tr[,c(2:4)],fdata.Reg.new)
#create lagged variables
fdata.join$WD_lag1 <- Lag(fdata.join$Wind,1)
fdata.join$Price_lag1 <- Lag(fdata.join$Price,1)
fdata.join$DEM_lag1 <- Lag(fdata.join$Demand,1)
#loop for forecasting
tstart = dim(fdata_tr)[1]
for (i in (tstart+1):(tstart+92)){
#Predict and substitute in output variable so it can be used in following forecasts
fdata.join$Price[i] <- predict(mlp.fit,  newdata = fdata.join[i,])
#Recalculate lagged variables using the estimated value
fdata.join$Price_lag1 <- Lag(fdata.join$Price,1)
}
#forecasts
fdata.join$Price[(tstart+1):(tstart+92)]
y.MLP.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.MLP.est[i] <- fdata.join$Price[i]
}
#Plot series and forecast
autoplot(y)+
forecast::autolayer(y.MLP.est)
autoplot(y[,600:730])
autoplot(y[600:730,])
y[600:730,]
y[600:730,]
y[600:730,:]
y
y[2]
autoplot(y[600:730])
y[600:730]
autoplot(y[600:730])
autoplot(y)
autoplot(y)+
forecast::autolayer(y.MLP.est)
#Plot series and forecast
autoplot(ts(y[600:730]))
autoplot(y)+
forecast::autolayer(y.MLP.est)
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(y.MLP.est)
ts(y[600:730])
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.MLP.est))
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.MLP.est[640:730]))
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.MLP.est[600:730]))
y.TF.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.TF.est[i] <- val.forecast_h92[i-length(y_tr)]
}
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.SA.est[600:730]))
SensAnalysisMLP(mlp.fit) #Statistical sensitivity analysis
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.SA.est[600:730]))
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.SA.est[600:730]))
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
#### Fit initial FT model with large s
# This arima function belongs to the TSA package
xlag = Lag(x_tr,1)   # b
xlag[is.na(xlag)]=0
TF.fit <- arima(y_tr,
order=c(1,1,1),
seasonal = list(order=c(0,1,1),period=TT),
xtransf = xlag,
transfer = list(c(0,1)), #List with (r,s) orders
include.mean = TRUE,
method="ML")
summary(TF.fit) # summary of training errors and estimated coefficients
coeftest(TF.fit) # statistical significance of estimated coefficients
# Check regression error to see the need of differentiation
CheckResiduals.ICAI(TF.fit, lag=75)
# Check numerator coefficients of explanatory variable
TF.Identification.plot(x_tr,TF.fit)
# Perform future forecast
x_fut <- x[1:92]
val.forecast_h92 <- TF.forecast(y.old = as.matrix(y_tr), #past values of the series
x.old = as.matrix(x_tr), #Past values of the explanatory variables
x.new = as.matrix(x_ts), #New values of the explanatory variables
model = TF.fit, #fitted transfer function model
h=92) #Forecast horizon
val.forecast_h92
y.TF.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.TF.est[i] <- val.forecast_h92[i-length(y_tr)]
}
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
#### Fit initial FT model with large s
# This arima function belongs to the TSA package
xlag = Lag(x_tr,0)   # b
xlag[is.na(xlag)]=0
TF.fit <- arima(y_tr,
order=c(1,1,1),
seasonal = list(order=c(0,1,1),period=TT),
xtransf = xlag,
transfer = list(c(0,1)), #List with (r,s) orders
include.mean = TRUE,
method="ML")
summary(TF.fit) # summary of training errors and estimated coefficients
coeftest(TF.fit) # statistical significance of estimated coefficients
# Check regression error to see the need of differentiation
CheckResiduals.ICAI(TF.fit, lag=75)
# Check numerator coefficients of explanatory variable
TF.Identification.plot(x_tr,TF.fit)
# Perform future forecast
x_fut <- x[1:92]
val.forecast_h92 <- TF.forecast(y.old = as.matrix(y_tr), #past values of the series
x.old = as.matrix(x_tr), #Past values of the explanatory variables
x.new = as.matrix(x_ts), #New values of the explanatory variables
model = TF.fit, #fitted transfer function model
h=92) #Forecast horizon
val.forecast_h92
y.TF.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.TF.est[i] <- val.forecast_h92[i-length(y_tr)]
}
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
TF.fit <- arima(y_tr,
order=c(1,1,1),
seasonal = list(order=c(0,1,1),period=TT),
xtransf = x,
transfer = list(c(0,1)), #List with (r,s) orders
include.mean = TRUE,
method="ML")
summary(TF.fit) # summary of training errors and estimated coefficients
coeftest(TF.fit) # statistical significance of estimated coefficients
# Check regression error to see the need of differentiation
CheckResiduals.ICAI(TF.fit, lag=75)
# Check numerator coefficients of explanatory variable
TF.Identification.plot(x_tr,TF.fit)
# Perform future forecast
x_fut <- x[1:92]
val.forecast_h92 <- TF.forecast(y.old = as.matrix(y_tr), #past values of the series
x.old = as.matrix(x_tr), #Past values of the explanatory variables
x.new = as.matrix(x_ts), #New values of the explanatory variables
model = TF.fit, #fitted transfer function model
h=92) #Forecast horizon
val.forecast_h92
y.TF.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.TF.est[i] <- val.forecast_h92[i-length(y_tr)]
}
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
TF.fit <- arima(y_tr,
order=c(1,1,1),
seasonal = list(order=c(0,1,1),period=TT),
xtransf = xlag,
transfer = list(c(0,2)), #List with (r,s) orders
include.mean = TRUE,
method="ML")
summary(TF.fit) # summary of training errors and estimated coefficients
coeftest(TF.fit) # statistical significance of estimated coefficients
# Check numerator coefficients of explanatory variable
TF.Identification.plot(x_tr,TF.fit)
# Check regression error to see the need of differentiation
CheckResiduals.ICAI(TF.fit, lag=75)
val.forecast_h92 <- TF.forecast(y.old = as.matrix(y_tr), #past values of the series
x.old = as.matrix(x_tr), #Past values of the explanatory variables
x.new = as.matrix(x_ts), #New values of the explanatory variables
model = TF.fit, #fitted transfer function model
h=92) #Forecast horizon
val.forecast_h92
# Perform future forecast
x_fut <- x[1:92]
y.TF.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.TF.est[i] <- val.forecast_h92[i-length(y_tr)]
}
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
set.seed(150)
TF.fit <- arima(y_tr,
order=c(1,1,1),
seasonal = list(order=c(0,1,1),period=TT),
xtransf = xlag,
transfer = list(c(0,1)), #List with (r,s) orders
include.mean = TRUE,
method="ML")
summary(TF.fit) # summary of training errors and estimated coefficients
coeftest(TF.fit) # statistical significance of estimated coefficients
# Check regression error to see the need of differentiation
CheckResiduals.ICAI(TF.fit, lag=75)
# Check numerator coefficients of explanatory variable
TF.Identification.plot(x_tr,TF.fit)
# Perform future forecast
x_fut <- x[1:92]
val.forecast_h92 <- TF.forecast(y.old = as.matrix(y_tr), #past values of the series
x.old = as.matrix(x_tr), #Past values of the explanatory variables
x.new = as.matrix(x_ts), #New values of the explanatory variables
model = TF.fit, #fitted transfer function model
h=92) #Forecast horizon
val.forecast_h92
y.TF.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.TF.est[i] <- val.forecast_h92[i-length(y_tr)]
}
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.MLP.est[600:730]))
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.MLP.est[600:730]))
#### Comparison
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.SA.est[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))+
forecast::autolayer(ts(y.MLP.est[600:730]))
y_tr <- ts(fdata_tr$Price, start = 2019, frequency = 365)
y <- ts(fdata$Price, start = 2019, frequency = 365)
x_tr <- ts(fdata_tr$Demand, start = 2019, frequency = 365)
x <- ts(fdata$Demand, start = 2019, frequency = 365)
x_ts <- ts(fdata_ts$Demand, start = 2020, frequency = 365)
#### Fit initial FT model with large s
# This arima function belongs to the TSA package
xlag = Lag(x_tr,0)   # b
xlag[is.na(xlag)]=0
set.seed(150)
TF.fit <- arima(y_tr,
order=c(1,1,1),
seasonal = list(order=c(0,1,1),period=TT),
xtransf = xlag,
transfer = list(c(0,1)), #List with (r,s) orders
include.mean = TRUE,
method="ML")
summary(TF.fit) # summary of training errors and estimated coefficients
coeftest(TF.fit) # statistical significance of estimated coefficients
# Check regression error to see the need of differentiation
CheckResiduals.ICAI(TF.fit, lag=75)
# Check numerator coefficients of explanatory variable
TF.Identification.plot(x_tr,TF.fit)
# Perform future forecast
x_fut <- x[1:92]
val.forecast_h92 <- TF.forecast(y.old = as.matrix(y_tr), #past values of the series
x.old = as.matrix(x_tr), #Past values of the explanatory variables
x.new = as.matrix(x_ts), #New values of the explanatory variables
model = TF.fit, #fitted transfer function model
h=92) #Forecast horizon
val.forecast_h92
y.TF.est <- y*NA
for (i in seq(length(y_tr)+1, length(y), 1)){# loop for validation period
y.TF.est[i] <- val.forecast_h92[i-length(y_tr)]
}
#Plot series and forecast
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))
TF.fit <- arima(y_tr,
order=c(1,1,1),
seasonal = list(order=c(0,1,1),period=TT),
xtransf = xlag,
transfer = list(c(1,1)), #List with (r,s) orders
include.mean = TRUE,
method="ML")
summary(TF.fit) # summary of training errors and estimated coefficients
coeftest(TF.fit) # statistical significance of estimated coefficients
#### Comparison
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.SA.est[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))+
forecast::autolayer(ts(y.MLP.est[600:730]))
fdata_tr[,4]
#Error measurements
accuracy(fdata_tr[,4],y.SA.est[i])
#Error measurements
accuracy(fdata_tr[length(y_tr)+1: length(y),4],y.SA.est[i])
fdata_tr[length(y_tr)+1: length(y),4]
length(y)
fdata_tr[640:731,4]
fdata_tr[c(640:731),4]
#Error measurements
accuracy(fdata_tr,y.SA.est[i])
#Error measurements
accuracy(fdata_tr[,4],mlp_pred)
fdata_tr[,4]
#Error measurements
accuracy(fdata_ts[,4],mlp_pred)
fdata_ts[,4]
mlp_pred
y.SA.est
y.SA.est[640:731]
#Error measurements
accuracy(fdata_ts[,4],y.SA.est[640:731])
y.SA.est[640:731]
arima.fit
summary(arima.fit) # summary of training errors and estimated coefficients
coeftest(arima.fit) # statistical significance of estimated coefficients
autoplot(arima.fit) # root plot
#Error measurements
accuracy(fdata_ts[,4],y.TF.est[640:731])
#### Comparison
autoplot(ts(y[600:730]))+
forecast::autolayer(ts(y.SA.est[600:730]))+
forecast::autolayer(ts(y.TF.est[600:730]))+
forecast::autolayer(ts(y.MLP.est[600:730]))
#Error measurements
accuracy(fdata_ts[,4],y.MLP.est[640:731])
